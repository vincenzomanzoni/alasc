{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02 Pytorch Forecasting Example - NBeats with Tensorboard.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM42tE/4XrzxY7gHfkkUY+x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vincenzomanzoni/alasc/blob/master/02_Pytorch_Forecasting_Example_NBeats_with_Tensorboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzR__2alHI7B"
      },
      "source": [
        "# Pytorch Forecasting | N-Beats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFEaDKv2HOiE"
      },
      "source": [
        "## Install Pytorch Forecasting and import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2ubUvrtdMH_"
      },
      "source": [
        "!pip install pytorch-forecasting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LxPc2r3ecj9"
      },
      "source": [
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torch\r\n",
        "\r\n",
        "import pytorch_lightning as pl\r\n",
        "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\r\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\r\n",
        "\r\n",
        "from pytorch_forecasting import TimeSeriesDataSet, Baseline, NBeats\r\n",
        "from pytorch_forecasting.data.examples import generate_ar_data\r\n",
        "from pytorch_forecasting.metrics import SMAPE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2Foq_IuHal2"
      },
      "source": [
        "## Dataset generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6xzg3usdaqx"
      },
      "source": [
        "data = generate_ar_data(seasonality=12, timesteps=364, n_series=1, seed=42, trend = 3.0, noise = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlVHv2iDeawj"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4QethHUegHH"
      },
      "source": [
        "plt.plot(data.time_idx, data.value)\r\n",
        "plt.title('Generated data')\r\n",
        "plt.xlabel('Time index')\r\n",
        "plt.ylabel('Value')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-vdX-m_f2D3"
      },
      "source": [
        "plt.plot(data.value)\r\n",
        "plt.xlim(354-80, 354)\r\n",
        "plt.title('Generated data')\r\n",
        "plt.xlabel('Time index')\r\n",
        "plt.ylabel('Value')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsQizVcaHhhv"
      },
      "source": [
        "## Creation of datasets and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtI-Yjiyk2Jr"
      },
      "source": [
        "# Create dataset and dataloaders\r\n",
        "max_encoder_length = 60\r\n",
        "max_prediction_length = 20\r\n",
        "batch_size = 16\r\n",
        "\r\n",
        "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\r\n",
        "\r\n",
        "context_length = max_encoder_length\r\n",
        "prediction_length = max_prediction_length\r\n",
        "\r\n",
        "training = TimeSeriesDataSet(\r\n",
        "    data[lambda x: x.time_idx <= training_cutoff],\r\n",
        "    time_idx=\"time_idx\",\r\n",
        "    target=\"value\",\r\n",
        "    group_ids=[\"series\"],\r\n",
        "    time_varying_unknown_reals=[\"value\"],    \r\n",
        "    max_encoder_length=context_length,\r\n",
        "    max_prediction_length=prediction_length,    \r\n",
        ")\r\n",
        "validation = TimeSeriesDataSet.from_dataset(training, data, min_prediction_idx=training_cutoff + 1)\r\n",
        "\r\n",
        "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\r\n",
        "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wogizJpBpk76"
      },
      "source": [
        "## Calculate Baseline Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFP6v0Wkk29O"
      },
      "source": [
        "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\r\n",
        "baseline_predictions = Baseline().predict(val_dataloader)\r\n",
        "SMAPE()(baseline_predictions, actuals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XpGT0Hypqiv"
      },
      "source": [
        "## Train NBeats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIyH7t-_o1cq"
      },
      "source": [
        "pl.seed_everything(42)\r\n",
        "\r\n",
        "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\r\n",
        "lr_logger_callback = LearningRateMonitor() \r\n",
        "\r\n",
        "trainer = pl.Trainer(\r\n",
        "    max_epochs=100,\r\n",
        "    gpus=1,\r\n",
        "    weights_summary=\"top\",\r\n",
        "    gradient_clip_val=0.1,\r\n",
        "    callbacks=[early_stop_callback, lr_logger_callback],\r\n",
        "    limit_train_batches=30,\r\n",
        ")\r\n",
        "\r\n",
        "net = NBeats.from_dataset(\r\n",
        "    training,\r\n",
        "    learning_rate=0.1,\r\n",
        "    weight_decay=1e-2,\r\n",
        "    widths=[32, 512],\r\n",
        "    backcast_loss_ratio=1.0,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E61ry1oFkHh"
      },
      "source": [
        "### Find Optimal Learning Rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ7XCiSDpvIl"
      },
      "source": [
        "res = trainer.tuner.lr_find(net, train_dataloader=train_dataloader, val_dataloaders=val_dataloader, min_lr=1e-5)\r\n",
        "fig = res.plot(show=True, suggest=True)\r\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZAZVc7SNqVH"
      },
      "source": [
        "Sometime the red point in the chart does not correspond to the minimim of the loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VncdRoHWN9Zx"
      },
      "source": [
        "print(f\"Suggested learning rate: {res.suggestion()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApPkCc5FNDZT"
      },
      "source": [
        "# Look at the above char and put here the learning rate which corresponds\r\n",
        "# to the minimum of the function. Usually, 0.1 is a good choice.\r\n",
        "net.hparams.learning_rate = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok9krWm8NGaq"
      },
      "source": [
        "### Set final parameters before the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSA8rahWJZ0b"
      },
      "source": [
        "net.hparams.log_interval = 10\r\n",
        "net.hparams.log_val_interval = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3-4rlaGNNq2"
      },
      "source": [
        "### Training time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H8boR_YJlQK"
      },
      "source": [
        "trainer.fit(\r\n",
        "    net,\r\n",
        "    train_dataloader=train_dataloader,\r\n",
        "    val_dataloaders=val_dataloader,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04fJ1537KcrD"
      },
      "source": [
        "## The best model and its performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyGMO2cgquY4"
      },
      "source": [
        "best_model_path = trainer.checkpoint_callback.best_model_path\r\n",
        "best_model = NBeats.load_from_checkpoint(best_model_path)\r\n",
        "print(best_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX0tWPVxKjAd"
      },
      "source": [
        "### Metrics of the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y3nyT_lrFan"
      },
      "source": [
        "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\r\n",
        "predictions = best_model.predict(val_dataloader)\r\n",
        "print(\"MAE: {0:.3}\".format((actuals - predictions).abs().mean().item()))\r\n",
        "print(\"MAPE: {0:.3}%\".format((100 * (actuals - predictions) / actuals).abs().mean().item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXibjlC4rIPI"
      },
      "source": [
        "raw_predictions, x = best_model.predict(val_dataloader, mode=\"raw\", return_x=True)\r\n",
        "best_model.plot_prediction(x, raw_predictions, add_loss_to_title=True);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bct_0g_ire6_"
      },
      "source": [
        "best_model.plot_interpretation(x, raw_predictions, idx=0);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKMulXeHLdCX"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7xg6bFARWng"
      },
      "source": [
        "%tensorboard --logdir lightning_logs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}